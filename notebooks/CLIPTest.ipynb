{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CLIPTest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JthC9qBtWyRq"
      },
      "source": [
        "!pip install transformers datasets -qq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0GaXW9-W6R_"
      },
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "from PIL import Image\n",
        "import torch\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAyBd3w2XLKI",
        "outputId": "7938d05f-e9fe-4cf3-f9c1-dde0ea003ee5"
      },
      "source": [
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ftfy or spacy is not installed using BERT BasicTokenizer instead of ftfy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Q5gmKcOYLmJ",
        "outputId": "9647f08b-eb4f-4b07-b1ba-94d7208538f0"
      },
      "source": [
        "ds = load_dataset(\"shpotes/tfcol\", split=\"validation\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration default\n",
            "Reusing dataset tf_col (/root/.cache/huggingface/datasets/shpotes___tf_col)/default/1.0.0/0c616218d5e0a194334e0ed0adacd86ab9b315ec6b03a8b388dece024753def2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl6kYcfpZhAt"
      },
      "source": [
        "def int2str(x):\n",
        "  _int2str = ds.features[\"labels\"].feature.int2str\n",
        "  if isinstance(x, int):\n",
        "    return _int2str(x)\n",
        "  elif hasattr(x, '__iter__'):\n",
        "    return [_int2str(i) for i in x]\n",
        "  raise TypeError\n",
        "\n",
        "def batch(iterable, n=1):\n",
        "  l = len(iterable)\n",
        "  num = range(l)\n",
        "  for ndx in range(0, l, n):\n",
        "    yield num[ndx:min(ndx + n, l)], iterable[ndx:min(ndx + n, l)]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzTSVZHTZMWo"
      },
      "source": [
        "images = [Image.open(img).convert(\"RGB\") for img in ds[\"image\"]]\n",
        "\n",
        "prompt_seeds = [\n",
        "    \"clothing store\",\n",
        "    \"liquor store\",\n",
        "    \"barber shop\",\n",
        "    \"electronic store\",\n",
        "    \"coffee store\",\n",
        "    \"furniture store\",\n",
        "    \"hot dog cart\", # puesto movil \n",
        "    \"ERROR OSJDFADOIAJSOIDJAMS\", # electrodomesticos\n",
        "    \"butcher shop\",\n",
        "    \"bar\",\n",
        "    \"pet shop\",\n",
        "    \"store\",\n",
        "    \"pharmacy\",\n",
        "    \"sport store\",\n",
        "    \"car shop\",\n",
        "    \"shoe shop\",\n",
        "    \"supermarket\",\n",
        "    \"hotel\"\n",
        "]\n",
        "\n",
        "prompts = [f\"an image of a {seed}\" for seed in prompt_seeds]\n",
        "\n",
        "model = model.cuda()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_hE61hplEXh"
      },
      "source": [
        "score = [0 for _ in range(len(prompts))]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdRg7_jmcv5Z",
        "outputId": "ef849037-85c9-40be-ed37-46fa86707e25"
      },
      "source": [
        "for image_idx, image_batch in tqdm(batch(images, 8)):\n",
        "  input = processor(\n",
        "      text=prompts, \n",
        "      images=image_batch,\n",
        "      return_tensors=\"pt\", \n",
        "      padding=True,\n",
        "  )\n",
        "  \n",
        "  input = {k: v.cuda() for k, v in input.items()}\n",
        "\n",
        "  outputs = model(**input)\n",
        "  logits_per_image = outputs.logits_per_image\n",
        "  probs = logits_per_image.softmax(dim=1)\n",
        "\n",
        "  for img_idx, prob_idx in zip(image_idx, range(8)):\n",
        "    topk = set(torch.topk(probs[prob_idx], 5).indices.cpu().tolist())\n",
        "    labels = set(ds[\"labels\"][img_idx])\n",
        "\n",
        "\n",
        "    for i in (topk & labels):\n",
        "      score[i] += 1"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "83it [00:25,  3.21it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEyVLLLWmFyJ"
      },
      "source": [
        "final_score = [local / len(ds) for local in score]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2wYcUWNipcD",
        "outputId": "89e497a4-1cc6-4f24-bf9d-068127fde7a2"
      },
      "source": [
        "final_score"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11550151975683891,\n",
              " 0.015197568389057751,\n",
              " 0.04711246200607903,\n",
              " 0.04559270516717325,\n",
              " 0.0060790273556231,\n",
              " 0.04711246200607903,\n",
              " 0.00303951367781155,\n",
              " 0.0,\n",
              " 0.019756838905775075,\n",
              " 0.00303951367781155,\n",
              " 0.025835866261398176,\n",
              " 0.022796352583586626,\n",
              " 0.00303951367781155,\n",
              " 0.0060790273556231,\n",
              " 0.004559270516717325,\n",
              " 0.0,\n",
              " 0.0121580547112462,\n",
              " 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9nMn4X7lPw1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}